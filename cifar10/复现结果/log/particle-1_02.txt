[2023-11-06 16:53:00.518880]-Used GPU#3, worker name:Process-403[2820]
[2023-11-06 16:53:04.260987]-#parameters:1527638
[2023-11-06 16:57:54.440971]-Train-Epoch:   1,  Loss: 1.7737, Acc:0.3236
[2023-11-06 16:58:13.752998]-Test-Loss:1.2931, Acc:0.5268
[2023-11-06 17:03:04.328872]-Train-Epoch:   2,  Loss: 1.3973, Acc:0.4877
[2023-11-06 17:03:22.970876]-Test-Loss:1.0488, Acc:0.6271
[2023-11-06 17:08:13.121029]-Train-Epoch:   3,  Loss: 1.2022, Acc:0.5715
[2023-11-06 17:08:31.796217]-Test-Loss:0.8682, Acc:0.6945
[2023-11-06 17:13:22.641083]-Train-Epoch:   4,  Loss: 1.0790, Acc:0.6190
[2023-11-06 17:13:41.421068]-Test-Loss:0.8518, Acc:0.7143
[2023-11-06 17:18:31.749460]-Train-Epoch:   5,  Loss: 0.9900, Acc:0.6498
[2023-11-06 17:18:50.676363]-Test-Loss:0.6932, Acc:0.7662
[2023-11-06 17:23:43.042364]-Train-Epoch:   6,  Loss: 0.9292, Acc:0.6770
[2023-11-06 17:24:01.860105]-Test-Loss:0.6742, Acc:0.7713
[2023-11-06 17:28:52.897347]-Train-Epoch:   7,  Loss: 0.8690, Acc:0.7019
[2023-11-06 17:29:11.415555]-Test-Loss:0.5812, Acc:0.8112
[2023-11-06 17:34:01.254754]-Train-Epoch:   8,  Loss: 0.8288, Acc:0.7156
[2023-11-06 17:34:19.977127]-Test-Loss:0.5058, Acc:0.8336
[2023-11-06 17:39:11.717701]-Train-Epoch:   9,  Loss: 0.7883, Acc:0.7294
[2023-11-06 17:39:30.603479]-Test-Loss:0.5039, Acc:0.8371
[2023-11-06 17:44:21.696950]-Train-Epoch:  10,  Loss: 0.7644, Acc:0.7390
[2023-11-06 17:44:40.422103]-Test-Loss:0.4822, Acc:0.8448
[2023-11-06 17:49:32.884921]-Train-Epoch:  11,  Loss: 0.7362, Acc:0.7482
[2023-11-06 17:49:51.841287]-Test-Loss:0.4357, Acc:0.8594
[2023-11-06 17:54:42.877985]-Train-Epoch:  12,  Loss: 0.7114, Acc:0.7571
[2023-11-06 17:55:01.713253]-Test-Loss:0.4272, Acc:0.8614
[2023-11-06 17:59:52.885022]-Train-Epoch:  13,  Loss: 0.6991, Acc:0.7603
[2023-11-06 18:00:11.512831]-Test-Loss:0.4706, Acc:0.8557
[2023-11-06 18:05:02.714673]-Train-Epoch:  14,  Loss: 0.6785, Acc:0.7684
[2023-11-06 18:05:21.828963]-Test-Loss:0.3880, Acc:0.8749
[2023-11-06 18:10:12.614671]-Train-Epoch:  15,  Loss: 0.6596, Acc:0.7756
[2023-11-06 18:10:31.408052]-Test-Loss:0.4567, Acc:0.8555
[2023-11-06 18:15:21.380952]-Train-Epoch:  16,  Loss: 0.6497, Acc:0.7794
[2023-11-06 18:15:40.161051]-Test-Loss:0.3851, Acc:0.8791
[2023-11-06 18:20:30.545315]-Train-Epoch:  17,  Loss: 0.6361, Acc:0.7858
[2023-11-06 18:20:49.202932]-Test-Loss:0.3801, Acc:0.8790
[2023-11-06 18:25:39.962924]-Train-Epoch:  18,  Loss: 0.6252, Acc:0.7898
[2023-11-06 18:25:59.197583]-Test-Loss:0.3769, Acc:0.8838
[2023-11-06 18:30:49.649286]-Train-Epoch:  19,  Loss: 0.6125, Acc:0.7915
[2023-11-06 18:31:08.282741]-Test-Loss:0.3707, Acc:0.8868
[2023-11-06 18:35:59.746738]-Train-Epoch:  20,  Loss: 0.6051, Acc:0.7959
[2023-11-06 18:36:18.187745]-Test-Loss:0.3577, Acc:0.8854
[2023-11-06 18:41:08.416189]-Train-Epoch:  21,  Loss: 0.5969, Acc:0.7967
[2023-11-06 18:41:27.543207]-Test-Loss:0.3669, Acc:0.8834
[2023-11-06 18:46:17.994971]-Train-Epoch:  22,  Loss: 0.5861, Acc:0.8020
[2023-11-06 18:46:36.882174]-Test-Loss:0.3319, Acc:0.8943
[2023-11-06 18:51:27.377580]-Train-Epoch:  23,  Loss: 0.5761, Acc:0.8058
[2023-11-06 18:51:46.156293]-Test-Loss:0.3486, Acc:0.8907
[2023-11-06 18:56:36.623883]-Train-Epoch:  24,  Loss: 0.5687, Acc:0.8073
[2023-11-06 18:56:55.419022]-Test-Loss:0.3522, Acc:0.8902
[2023-11-06 19:01:46.193429]-Train-Epoch:  25,  Loss: 0.5662, Acc:0.8084
[2023-11-06 19:02:04.505038]-Test-Loss:0.3163, Acc:0.8995
[2023-11-06 19:06:55.145286]-Train-Epoch:  26,  Loss: 0.5508, Acc:0.8127
[2023-11-06 19:07:13.713176]-Test-Loss:0.3447, Acc:0.8918
[2023-11-06 19:12:04.396197]-Train-Epoch:  27,  Loss: 0.5446, Acc:0.8157
[2023-11-06 19:12:22.741925]-Test-Loss:0.3542, Acc:0.8890
[2023-11-06 19:17:12.115162]-Train-Epoch:  28,  Loss: 0.5477, Acc:0.8144
[2023-11-06 19:17:30.689764]-Test-Loss:0.2932, Acc:0.9058
[2023-11-06 19:22:19.743879]-Train-Epoch:  29,  Loss: 0.5402, Acc:0.8170
[2023-11-06 19:22:38.360423]-Test-Loss:0.3168, Acc:0.9023
[2023-11-06 19:27:29.970426]-Train-Epoch:  30,  Loss: 0.5352, Acc:0.8170
[2023-11-06 19:27:48.823738]-Test-Loss:0.3030, Acc:0.9048
[2023-11-06 19:32:38.692974]-Train-Epoch:  31,  Loss: 0.5295, Acc:0.8205
[2023-11-06 19:32:57.636907]-Test-Loss:0.2939, Acc:0.9059
[2023-11-06 19:37:49.028902]-Train-Epoch:  32,  Loss: 0.5142, Acc:0.8243
[2023-11-06 19:38:07.584148]-Test-Loss:0.2829, Acc:0.9089
[2023-11-06 19:42:57.707638]-Train-Epoch:  33,  Loss: 0.5146, Acc:0.8252
[2023-11-06 19:43:16.542222]-Test-Loss:0.2700, Acc:0.9144
[2023-11-06 19:48:07.305015]-Train-Epoch:  34,  Loss: 0.5119, Acc:0.8256
[2023-11-06 19:48:26.215160]-Test-Loss:0.2762, Acc:0.9141
[2023-11-06 19:53:17.995433]-Train-Epoch:  35,  Loss: 0.5065, Acc:0.8284
[2023-11-06 19:53:36.954880]-Test-Loss:0.2940, Acc:0.9097
[2023-11-06 19:58:27.557888]-Train-Epoch:  36,  Loss: 0.5059, Acc:0.8288
[2023-11-06 19:58:46.290708]-Test-Loss:0.2803, Acc:0.9136
[2023-11-06 20:03:36.961302]-Train-Epoch:  37,  Loss: 0.4978, Acc:0.8306
[2023-11-06 20:03:55.746147]-Test-Loss:0.2750, Acc:0.9109
[2023-11-06 20:08:47.496488]-Train-Epoch:  38,  Loss: 0.4947, Acc:0.8319
[2023-11-06 20:09:06.443303]-Test-Loss:0.2891, Acc:0.9124
[2023-11-06 20:13:56.968940]-Train-Epoch:  39,  Loss: 0.4963, Acc:0.8319
[2023-11-06 20:14:15.507227]-Test-Loss:0.2680, Acc:0.9165
[2023-11-06 20:19:06.409694]-Train-Epoch:  40,  Loss: 0.4889, Acc:0.8357
[2023-11-06 20:19:25.280516]-Test-Loss:0.2610, Acc:0.9161
[2023-11-06 20:24:16.429290]-Train-Epoch:  41,  Loss: 0.4826, Acc:0.8352
[2023-11-06 20:24:35.348716]-Test-Loss:0.2747, Acc:0.9143
[2023-11-06 20:29:27.935696]-Train-Epoch:  42,  Loss: 0.4784, Acc:0.8382
[2023-11-06 20:29:46.129389]-Test-Loss:0.2449, Acc:0.9208
[2023-11-06 20:34:37.147533]-Train-Epoch:  43,  Loss: 0.4815, Acc:0.8355
[2023-11-06 20:34:55.954871]-Test-Loss:0.2609, Acc:0.9167
[2023-11-06 20:39:46.853607]-Train-Epoch:  44,  Loss: 0.4721, Acc:0.8388
[2023-11-06 20:40:06.069415]-Test-Loss:0.2577, Acc:0.9185
[2023-11-06 20:44:55.333639]-Train-Epoch:  45,  Loss: 0.4741, Acc:0.8399
[2023-11-06 20:45:14.415181]-Test-Loss:0.2442, Acc:0.9194
[2023-11-06 20:50:06.192751]-Train-Epoch:  46,  Loss: 0.4698, Acc:0.8400
[2023-11-06 20:50:24.903129]-Test-Loss:0.2872, Acc:0.9118
[2023-11-06 20:55:16.468772]-Train-Epoch:  47,  Loss: 0.4679, Acc:0.8431
[2023-11-06 20:55:34.980687]-Test-Loss:0.2603, Acc:0.9193
[2023-11-06 21:00:26.338054]-Train-Epoch:  48,  Loss: 0.4643, Acc:0.8416
[2023-11-06 21:00:44.973432]-Test-Loss:0.2512, Acc:0.9200
[2023-11-06 21:05:36.226566]-Train-Epoch:  49,  Loss: 0.4596, Acc:0.8437
[2023-11-06 21:05:55.177973]-Test-Loss:0.2454, Acc:0.9217
[2023-11-06 21:10:45.157794]-Train-Epoch:  50,  Loss: 0.4568, Acc:0.8437
[2023-11-06 21:11:03.323738]-Test-Loss:0.2555, Acc:0.9175
[2023-11-06 21:15:55.017832]-Train-Epoch:  51,  Loss: 0.4584, Acc:0.8430
[2023-11-06 21:16:13.260150]-Test-Loss:0.2404, Acc:0.9234
[2023-11-06 21:21:03.730169]-Train-Epoch:  52,  Loss: 0.4591, Acc:0.8440
[2023-11-06 21:21:22.224170]-Test-Loss:0.2547, Acc:0.9195
[2023-11-06 21:26:12.377006]-Train-Epoch:  53,  Loss: 0.4512, Acc:0.8465
[2023-11-06 21:26:30.936093]-Test-Loss:0.2529, Acc:0.9212
[2023-11-06 21:31:20.997563]-Train-Epoch:  54,  Loss: 0.4487, Acc:0.8467
[2023-11-06 21:31:40.041950]-Test-Loss:0.2627, Acc:0.9189
[2023-11-06 21:36:31.461146]-Train-Epoch:  55,  Loss: 0.4432, Acc:0.8495
[2023-11-06 21:36:50.120469]-Test-Loss:0.2583, Acc:0.9194
[2023-11-06 21:41:40.315486]-Train-Epoch:  56,  Loss: 0.4452, Acc:0.8488
[2023-11-06 21:41:59.120672]-Test-Loss:0.2375, Acc:0.9242
[2023-11-06 21:46:50.431911]-Train-Epoch:  57,  Loss: 0.4414, Acc:0.8503
[2023-11-06 21:47:08.918078]-Test-Loss:0.2575, Acc:0.9170
[2023-11-06 21:51:58.360777]-Train-Epoch:  58,  Loss: 0.4418, Acc:0.8494
[2023-11-06 21:52:17.262487]-Test-Loss:0.2659, Acc:0.9184
[2023-11-06 21:57:08.604065]-Train-Epoch:  59,  Loss: 0.4397, Acc:0.8517
[2023-11-06 21:57:27.521681]-Test-Loss:0.2521, Acc:0.9212
[2023-11-06 22:02:19.499884]-Train-Epoch:  60,  Loss: 0.4339, Acc:0.8538
[2023-11-06 22:02:38.199245]-Test-Loss:0.2328, Acc:0.9267
[2023-11-06 22:07:29.836523]-Train-Epoch:  61,  Loss: 0.4347, Acc:0.8527
[2023-11-06 22:07:48.320824]-Test-Loss:0.2731, Acc:0.9157
[2023-11-06 22:12:37.352889]-Train-Epoch:  62,  Loss: 0.4396, Acc:0.8489
[2023-11-06 22:12:55.945757]-Test-Loss:0.2476, Acc:0.9208
[2023-11-06 22:17:46.668375]-Train-Epoch:  63,  Loss: 0.4307, Acc:0.8549
[2023-11-06 22:18:05.572220]-Test-Loss:0.2421, Acc:0.9220
[2023-11-06 22:22:55.569746]-Train-Epoch:  64,  Loss: 0.4236, Acc:0.8565
[2023-11-06 22:23:14.208976]-Test-Loss:0.2290, Acc:0.9291
[2023-11-06 22:28:05.549025]-Train-Epoch:  65,  Loss: 0.4281, Acc:0.8561
[2023-11-06 22:28:24.163501]-Test-Loss:0.2575, Acc:0.9206
[2023-11-06 22:33:14.520382]-Train-Epoch:  66,  Loss: 0.4323, Acc:0.8540
[2023-11-06 22:33:33.043855]-Test-Loss:0.2445, Acc:0.9219
[2023-11-06 22:38:24.108797]-Train-Epoch:  67,  Loss: 0.4220, Acc:0.8564
[2023-11-06 22:38:42.521965]-Test-Loss:0.2235, Acc:0.9282
[2023-11-06 22:43:34.731481]-Train-Epoch:  68,  Loss: 0.4247, Acc:0.8553
[2023-11-06 22:43:53.624957]-Test-Loss:0.2306, Acc:0.9249
[2023-11-06 22:48:45.155457]-Train-Epoch:  69,  Loss: 0.4200, Acc:0.8572
[2023-11-06 22:49:03.573740]-Test-Loss:0.2223, Acc:0.9263
[2023-11-06 22:53:53.289635]-Train-Epoch:  70,  Loss: 0.4239, Acc:0.8555
[2023-11-06 22:54:12.067166]-Test-Loss:0.2445, Acc:0.9241
[2023-11-06 22:59:01.517201]-Train-Epoch:  71,  Loss: 0.4244, Acc:0.8549
[2023-11-06 22:59:20.575277]-Test-Loss:0.2380, Acc:0.9264
[2023-11-06 23:04:11.058559]-Train-Epoch:  72,  Loss: 0.4164, Acc:0.8583
[2023-11-06 23:04:29.737399]-Test-Loss:0.2279, Acc:0.9300
[2023-11-06 23:09:20.278771]-Train-Epoch:  73,  Loss: 0.4119, Acc:0.8589
[2023-11-06 23:09:39.511234]-Test-Loss:0.2291, Acc:0.9292
[2023-11-06 23:14:29.856745]-Train-Epoch:  74,  Loss: 0.4143, Acc:0.8589
[2023-11-06 23:14:48.305782]-Test-Loss:0.2259, Acc:0.9271
[2023-11-06 23:19:39.509062]-Train-Epoch:  75,  Loss: 0.4124, Acc:0.8583
[2023-11-06 23:19:57.924448]-Test-Loss:0.2232, Acc:0.9319
[2023-11-06 23:24:47.242800]-Train-Epoch:  76,  Loss: 0.4093, Acc:0.8600
[2023-11-06 23:25:05.890531]-Test-Loss:0.2379, Acc:0.9263
[2023-11-06 23:29:56.273960]-Train-Epoch:  77,  Loss: 0.4080, Acc:0.8595
[2023-11-06 23:30:14.975178]-Test-Loss:0.2237, Acc:0.9303
[2023-11-06 23:35:05.112150]-Train-Epoch:  78,  Loss: 0.4082, Acc:0.8615
[2023-11-06 23:35:24.029404]-Test-Loss:0.2220, Acc:0.9315
[2023-11-06 23:40:15.241656]-Train-Epoch:  79,  Loss: 0.4034, Acc:0.8622
[2023-11-06 23:40:33.916999]-Test-Loss:0.2377, Acc:0.9273
[2023-11-06 23:45:24.661269]-Train-Epoch:  80,  Loss: 0.3981, Acc:0.8636
[2023-11-06 23:45:43.524939]-Test-Loss:0.2215, Acc:0.9275
[2023-11-06 23:50:35.248828]-Train-Epoch:  81,  Loss: 0.4003, Acc:0.8631
[2023-11-06 23:50:54.077889]-Test-Loss:0.2218, Acc:0.9308
[2023-11-06 23:55:46.184711]-Train-Epoch:  82,  Loss: 0.4034, Acc:0.8623
[2023-11-06 23:56:04.424566]-Test-Loss:0.2311, Acc:0.9269
[2023-11-07 00:00:55.325561]-Train-Epoch:  83,  Loss: 0.4019, Acc:0.8623
[2023-11-07 00:01:14.323354]-Test-Loss:0.2172, Acc:0.9295
[2023-11-07 00:06:06.013324]-Train-Epoch:  84,  Loss: 0.3992, Acc:0.8643
[2023-11-07 00:06:25.266808]-Test-Loss:0.2243, Acc:0.9291
[2023-11-07 00:11:15.745220]-Train-Epoch:  85,  Loss: 0.3922, Acc:0.8664
[2023-11-07 00:11:34.454612]-Test-Loss:0.2211, Acc:0.9315
[2023-11-07 00:16:26.947343]-Train-Epoch:  86,  Loss: 0.4042, Acc:0.8620
[2023-11-07 00:16:45.628060]-Test-Loss:0.2285, Acc:0.9289
[2023-11-07 00:21:41.456577]-Train-Epoch:  87,  Loss: 0.3985, Acc:0.8641
[2023-11-07 00:22:00.158403]-Test-Loss:0.2114, Acc:0.9336
[2023-11-07 00:26:50.448894]-Train-Epoch:  88,  Loss: 0.3924, Acc:0.8661
[2023-11-07 00:27:08.977836]-Test-Loss:0.2197, Acc:0.9306
[2023-11-07 00:32:00.476894]-Train-Epoch:  89,  Loss: 0.3897, Acc:0.8685
[2023-11-07 00:32:19.481883]-Test-Loss:0.2313, Acc:0.9259
[2023-11-07 00:37:10.478142]-Train-Epoch:  90,  Loss: 0.3912, Acc:0.8661
[2023-11-07 00:37:28.853533]-Test-Loss:0.2038, Acc:0.9357
[2023-11-07 00:42:19.634678]-Train-Epoch:  91,  Loss: 0.3934, Acc:0.8658
[2023-11-07 00:42:38.404169]-Test-Loss:0.2125, Acc:0.9306
[2023-11-07 00:47:29.151214]-Train-Epoch:  92,  Loss: 0.3870, Acc:0.8693
[2023-11-07 00:47:47.585639]-Test-Loss:0.2315, Acc:0.9274
[2023-11-07 00:52:38.263911]-Train-Epoch:  93,  Loss: 0.3902, Acc:0.8673
[2023-11-07 00:52:57.005517]-Test-Loss:0.2388, Acc:0.9250
[2023-11-07 00:57:46.140792]-Train-Epoch:  94,  Loss: 0.3918, Acc:0.8659
[2023-11-07 00:58:05.049006]-Test-Loss:0.2040, Acc:0.9360
[2023-11-07 01:02:54.174177]-Train-Epoch:  95,  Loss: 0.3818, Acc:0.8694
[2023-11-07 01:03:13.277414]-Test-Loss:0.2328, Acc:0.9306
[2023-11-07 01:08:04.721264]-Train-Epoch:  96,  Loss: 0.3866, Acc:0.8682
[2023-11-07 01:08:23.341739]-Test-Loss:0.2142, Acc:0.9300
[2023-11-07 01:13:12.876674]-Train-Epoch:  97,  Loss: 0.3869, Acc:0.8679
[2023-11-07 01:13:31.573401]-Test-Loss:0.2197, Acc:0.9336
[2023-11-07 01:18:22.357555]-Train-Epoch:  98,  Loss: 0.3821, Acc:0.8703
[2023-11-07 01:18:40.695487]-Test-Loss:0.2160, Acc:0.9308
[2023-11-07 01:23:31.373268]-Train-Epoch:  99,  Loss: 0.3788, Acc:0.8716
[2023-11-07 01:23:50.640996]-Test-Loss:0.2066, Acc:0.9332
[2023-11-07 01:28:41.128787]-Train-Epoch: 100,  Loss: 0.3805, Acc:0.8699
[2023-11-07 01:28:59.911882]-Test-Loss:0.2038, Acc:0.9355
[2023-11-07 01:33:49.508766]-Train-Epoch: 101,  Loss: 0.3766, Acc:0.8719
[2023-11-07 01:34:08.123122]-Test-Loss:0.2094, Acc:0.9342
[2023-11-07 01:39:00.297283]-Train-Epoch: 102,  Loss: 0.3780, Acc:0.8700
[2023-11-07 01:39:18.941761]-Test-Loss:0.2031, Acc:0.9362
[2023-11-07 01:44:09.620567]-Train-Epoch: 103,  Loss: 0.3765, Acc:0.8711
[2023-11-07 01:44:28.543261]-Test-Loss:0.2413, Acc:0.9288
[2023-11-07 01:49:18.402158]-Train-Epoch: 104,  Loss: 0.3794, Acc:0.8708
[2023-11-07 01:49:37.299453]-Test-Loss:0.2042, Acc:0.9353
[2023-11-07 01:54:26.718668]-Train-Epoch: 105,  Loss: 0.3732, Acc:0.8728
[2023-11-07 01:54:45.549478]-Test-Loss:0.2176, Acc:0.9328
[2023-11-07 01:59:36.066738]-Train-Epoch: 106,  Loss: 0.3708, Acc:0.8733
[2023-11-07 01:59:54.684079]-Test-Loss:0.2032, Acc:0.9374
[2023-11-07 02:04:45.567239]-Train-Epoch: 107,  Loss: 0.3709, Acc:0.8742
[2023-11-07 02:05:03.973856]-Test-Loss:0.2024, Acc:0.9355
[2023-11-07 02:09:54.133806]-Train-Epoch: 108,  Loss: 0.3717, Acc:0.8723
[2023-11-07 02:10:12.484531]-Test-Loss:0.1880, Acc:0.9398
[2023-11-07 02:15:02.593247]-Train-Epoch: 109,  Loss: 0.3740, Acc:0.8715
[2023-11-07 02:15:20.962268]-Test-Loss:0.2068, Acc:0.9363
[2023-11-07 02:20:10.982773]-Train-Epoch: 110,  Loss: 0.3658, Acc:0.8757
[2023-11-07 02:20:29.250233]-Test-Loss:0.2069, Acc:0.9354
[2023-11-07 02:25:18.810971]-Train-Epoch: 111,  Loss: 0.3718, Acc:0.8739
[2023-11-07 02:25:37.480521]-Test-Loss:0.2143, Acc:0.9353
[2023-11-07 02:30:27.633037]-Train-Epoch: 112,  Loss: 0.3621, Acc:0.8771
[2023-11-07 02:30:45.938095]-Test-Loss:0.1946, Acc:0.9408
[2023-11-07 02:35:37.988710]-Train-Epoch: 113,  Loss: 0.3687, Acc:0.8732
[2023-11-07 02:35:56.577273]-Test-Loss:0.2049, Acc:0.9377
[2023-11-07 02:40:47.507008]-Train-Epoch: 114,  Loss: 0.3588, Acc:0.8772
[2023-11-07 02:41:06.675491]-Test-Loss:0.1947, Acc:0.9380
[2023-11-07 02:45:57.766209]-Train-Epoch: 115,  Loss: 0.3625, Acc:0.8766
[2023-11-07 02:46:16.497772]-Test-Loss:0.2124, Acc:0.9340
[2023-11-07 02:51:05.574602]-Train-Epoch: 116,  Loss: 0.3632, Acc:0.8754
[2023-11-07 02:51:24.321015]-Test-Loss:0.2002, Acc:0.9398
[2023-11-07 02:56:14.993499]-Train-Epoch: 117,  Loss: 0.3586, Acc:0.8795
[2023-11-07 02:56:33.809062]-Test-Loss:0.2188, Acc:0.9332
[2023-11-07 03:01:24.758012]-Train-Epoch: 118,  Loss: 0.3643, Acc:0.8738
[2023-11-07 03:01:43.517037]-Test-Loss:0.1920, Acc:0.9398
[2023-11-07 03:06:34.166057]-Train-Epoch: 119,  Loss: 0.3545, Acc:0.8784
[2023-11-07 03:06:52.887180]-Test-Loss:0.2014, Acc:0.9389
[2023-11-07 03:11:43.745145]-Train-Epoch: 120,  Loss: 0.3567, Acc:0.8783
[2023-11-07 03:12:02.236314]-Test-Loss:0.2137, Acc:0.9355
[2023-11-07 03:16:52.861386]-Train-Epoch: 121,  Loss: 0.3568, Acc:0.8776
[2023-11-07 03:17:11.657508]-Test-Loss:0.2019, Acc:0.9353
[2023-11-07 03:22:01.530726]-Train-Epoch: 122,  Loss: 0.3631, Acc:0.8777
[2023-11-07 03:22:20.154157]-Test-Loss:0.2031, Acc:0.9364
[2023-11-07 03:27:10.697207]-Train-Epoch: 123,  Loss: 0.3576, Acc:0.8767
[2023-11-07 03:27:29.386995]-Test-Loss:0.1977, Acc:0.9392
[2023-11-07 03:32:20.288213]-Train-Epoch: 124,  Loss: 0.3498, Acc:0.8801
[2023-11-07 03:32:39.065347]-Test-Loss:0.2020, Acc:0.9371
[2023-11-07 03:37:30.324990]-Train-Epoch: 125,  Loss: 0.3528, Acc:0.8787
[2023-11-07 03:37:49.325770]-Test-Loss:0.1939, Acc:0.9382
[2023-11-07 03:42:39.910766]-Train-Epoch: 126,  Loss: 0.3572, Acc:0.8783
[2023-11-07 03:42:58.220997]-Test-Loss:0.1918, Acc:0.9428
[2023-11-07 03:47:48.162758]-Train-Epoch: 127,  Loss: 0.3498, Acc:0.8797
[2023-11-07 03:48:07.167918]-Test-Loss:0.1986, Acc:0.9370
[2023-11-07 03:52:56.469582]-Train-Epoch: 128,  Loss: 0.3530, Acc:0.8797
[2023-11-07 03:53:15.600050]-Test-Loss:0.1860, Acc:0.9404
[2023-11-07 03:58:05.287138]-Train-Epoch: 129,  Loss: 0.3501, Acc:0.8803
[2023-11-07 03:58:24.437384]-Test-Loss:0.1889, Acc:0.9423
[2023-11-07 04:03:15.498081]-Train-Epoch: 130,  Loss: 0.3552, Acc:0.8795
[2023-11-07 04:03:34.261298]-Test-Loss:0.1916, Acc:0.9399
[2023-11-07 04:08:25.561033]-Train-Epoch: 131,  Loss: 0.3496, Acc:0.8797
[2023-11-07 04:08:43.692506]-Test-Loss:0.2065, Acc:0.9353
[2023-11-07 04:13:34.174754]-Train-Epoch: 132,  Loss: 0.3496, Acc:0.8804
[2023-11-07 04:13:53.177982]-Test-Loss:0.2094, Acc:0.9387
[2023-11-07 04:18:44.457219]-Train-Epoch: 133,  Loss: 0.3464, Acc:0.8823
[2023-11-07 04:19:03.230425]-Test-Loss:0.1931, Acc:0.9396
[2023-11-07 04:23:53.581302]-Train-Epoch: 134,  Loss: 0.3485, Acc:0.8817
[2023-11-07 04:24:12.304590]-Test-Loss:0.1921, Acc:0.9408
[2023-11-07 04:29:02.948902]-Train-Epoch: 135,  Loss: 0.3485, Acc:0.8818
[2023-11-07 04:29:21.935778]-Test-Loss:0.1969, Acc:0.9413
[2023-11-07 04:34:12.716815]-Train-Epoch: 136,  Loss: 0.3450, Acc:0.8826
[2023-11-07 04:34:31.463008]-Test-Loss:0.2049, Acc:0.9369
[2023-11-07 04:39:22.071251]-Train-Epoch: 137,  Loss: 0.3461, Acc:0.8821
[2023-11-07 04:39:40.415796]-Test-Loss:0.1969, Acc:0.9386
[2023-11-07 04:44:30.475656]-Train-Epoch: 138,  Loss: 0.3390, Acc:0.8848
[2023-11-07 04:44:49.127328]-Test-Loss:0.2072, Acc:0.9368
[2023-11-07 04:49:38.937555]-Train-Epoch: 139,  Loss: 0.3405, Acc:0.8833
[2023-11-07 04:49:58.118369]-Test-Loss:0.1997, Acc:0.9367
[2023-11-07 04:54:48.819105]-Train-Epoch: 140,  Loss: 0.3449, Acc:0.8826
[2023-11-07 04:55:07.807207]-Test-Loss:0.1875, Acc:0.9429
[2023-11-07 04:59:58.610273]-Train-Epoch: 141,  Loss: 0.3387, Acc:0.8836
[2023-11-07 05:00:17.443699]-Test-Loss:0.2172, Acc:0.9343
[2023-11-07 05:05:09.620405]-Train-Epoch: 142,  Loss: 0.3384, Acc:0.8847
[2023-11-07 05:05:28.600556]-Test-Loss:0.1934, Acc:0.9384
[2023-11-07 05:10:19.940835]-Train-Epoch: 143,  Loss: 0.3404, Acc:0.8831
[2023-11-07 05:10:38.671300]-Test-Loss:0.2003, Acc:0.9383
[2023-11-07 05:15:28.577929]-Train-Epoch: 144,  Loss: 0.3365, Acc:0.8838
[2023-11-07 05:15:47.645868]-Test-Loss:0.2381, Acc:0.9326
[2023-11-07 05:20:37.738679]-Train-Epoch: 145,  Loss: 0.3444, Acc:0.8818
[2023-11-07 05:20:56.588617]-Test-Loss:0.2003, Acc:0.9362
[2023-11-07 05:25:47.472805]-Train-Epoch: 146,  Loss: 0.3349, Acc:0.8841
[2023-11-07 05:26:05.794073]-Test-Loss:0.2211, Acc:0.9344
[2023-11-07 05:30:57.167931]-Train-Epoch: 147,  Loss: 0.3359, Acc:0.8857
[2023-11-07 05:31:16.145083]-Test-Loss:0.2047, Acc:0.9383
[2023-11-07 05:36:07.092577]-Train-Epoch: 148,  Loss: 0.3355, Acc:0.8866
[2023-11-07 05:36:25.793917]-Test-Loss:0.1855, Acc:0.9427
[2023-11-07 05:41:16.490466]-Train-Epoch: 149,  Loss: 0.3301, Acc:0.8865
[2023-11-07 05:41:35.359059]-Test-Loss:0.2043, Acc:0.9395
[2023-11-07 05:46:24.725931]-Train-Epoch: 150,  Loss: 0.3294, Acc:0.8880
[2023-11-07 05:46:43.429440]-Test-Loss:0.1971, Acc:0.9406
[2023-11-07 05:51:34.784991]-Train-Epoch: 151,  Loss: 0.3301, Acc:0.8861
[2023-11-07 05:51:53.734817]-Test-Loss:0.1880, Acc:0.9433
[2023-11-07 05:56:44.756827]-Train-Epoch: 152,  Loss: 0.3339, Acc:0.8867
[2023-11-07 05:57:03.513334]-Test-Loss:0.1981, Acc:0.9408
[2023-11-07 06:01:54.312739]-Train-Epoch: 153,  Loss: 0.3275, Acc:0.8882
[2023-11-07 06:02:13.141422]-Test-Loss:0.1920, Acc:0.9402
[2023-11-07 06:07:03.642216]-Train-Epoch: 154,  Loss: 0.3239, Acc:0.8886
[2023-11-07 06:07:22.700558]-Test-Loss:0.1959, Acc:0.9382
[2023-11-07 06:12:13.131147]-Train-Epoch: 155,  Loss: 0.3314, Acc:0.8874
[2023-11-07 06:12:32.056449]-Test-Loss:0.1938, Acc:0.9394
[2023-11-07 06:17:22.945227]-Train-Epoch: 156,  Loss: 0.3296, Acc:0.8870
[2023-11-07 06:17:41.726346]-Test-Loss:0.1834, Acc:0.9432
[2023-11-07 06:22:33.237849]-Train-Epoch: 157,  Loss: 0.3228, Acc:0.8882
[2023-11-07 06:22:51.576719]-Test-Loss:0.1848, Acc:0.9431
[2023-11-07 06:27:40.924795]-Train-Epoch: 158,  Loss: 0.3295, Acc:0.8873
[2023-11-07 06:27:59.826308]-Test-Loss:0.1933, Acc:0.9382
[2023-11-07 06:32:51.032445]-Train-Epoch: 159,  Loss: 0.3240, Acc:0.8907
[2023-11-07 06:33:09.757132]-Test-Loss:0.2210, Acc:0.9360
[2023-11-07 06:38:01.300873]-Train-Epoch: 160,  Loss: 0.3251, Acc:0.8887
[2023-11-07 06:38:20.121126]-Test-Loss:0.1889, Acc:0.9426
[2023-11-07 06:43:10.974100]-Train-Epoch: 161,  Loss: 0.3190, Acc:0.8902
[2023-11-07 06:43:29.742490]-Test-Loss:0.2019, Acc:0.9380
[2023-11-07 06:48:19.428578]-Train-Epoch: 162,  Loss: 0.3203, Acc:0.8897
[2023-11-07 06:48:38.161209]-Test-Loss:0.1892, Acc:0.9425
[2023-11-07 06:53:28.725291]-Train-Epoch: 163,  Loss: 0.3182, Acc:0.8912
[2023-11-07 06:53:47.561358]-Test-Loss:0.1976, Acc:0.9388
[2023-11-07 06:58:38.442973]-Train-Epoch: 164,  Loss: 0.3189, Acc:0.8908
[2023-11-07 06:58:56.810110]-Test-Loss:0.2001, Acc:0.9395
[2023-11-07 07:03:48.054360]-Train-Epoch: 165,  Loss: 0.3164, Acc:0.8917
[2023-11-07 07:04:06.681092]-Test-Loss:0.1880, Acc:0.9413
[2023-11-07 07:08:57.528081]-Train-Epoch: 166,  Loss: 0.3172, Acc:0.8908
[2023-11-07 07:09:16.130770]-Test-Loss:0.1948, Acc:0.9413
[2023-11-07 07:14:07.016695]-Train-Epoch: 167,  Loss: 0.3176, Acc:0.8911
[2023-11-07 07:14:25.969496]-Test-Loss:0.1914, Acc:0.9419
[2023-11-07 07:19:16.081557]-Train-Epoch: 168,  Loss: 0.3159, Acc:0.8913
[2023-11-07 07:19:35.019544]-Test-Loss:0.1978, Acc:0.9412
[2023-11-07 07:24:25.546761]-Train-Epoch: 169,  Loss: 0.3151, Acc:0.8918
[2023-11-07 07:24:44.173040]-Test-Loss:0.1886, Acc:0.9425
[2023-11-07 07:29:36.423760]-Train-Epoch: 170,  Loss: 0.3162, Acc:0.8925
[2023-11-07 07:29:55.463055]-Test-Loss:0.1829, Acc:0.9443
[2023-11-07 07:34:45.889332]-Train-Epoch: 171,  Loss: 0.3166, Acc:0.8906
[2023-11-07 07:35:04.405500]-Test-Loss:0.1787, Acc:0.9458
[2023-11-07 07:39:54.297078]-Train-Epoch: 172,  Loss: 0.3126, Acc:0.8923
[2023-11-07 07:40:13.214796]-Test-Loss:0.1786, Acc:0.9453
[2023-11-07 07:45:03.353374]-Train-Epoch: 173,  Loss: 0.3107, Acc:0.8938
[2023-11-07 07:45:22.360872]-Test-Loss:0.1836, Acc:0.9466
[2023-11-07 07:50:12.707663]-Train-Epoch: 174,  Loss: 0.3079, Acc:0.8939
[2023-11-07 07:50:31.068998]-Test-Loss:0.1820, Acc:0.9470
[2023-11-07 07:55:21.450041]-Train-Epoch: 175,  Loss: 0.3103, Acc:0.8936
[2023-11-07 07:55:40.501191]-Test-Loss:0.1826, Acc:0.9455
[2023-11-07 08:00:31.108669]-Train-Epoch: 176,  Loss: 0.3100, Acc:0.8928
[2023-11-07 08:00:50.087973]-Test-Loss:0.1860, Acc:0.9419
[2023-11-07 08:05:40.708132]-Train-Epoch: 177,  Loss: 0.3035, Acc:0.8967
[2023-11-07 08:05:59.147977]-Test-Loss:0.1929, Acc:0.9428
[2023-11-07 08:10:49.305812]-Train-Epoch: 178,  Loss: 0.3068, Acc:0.8967
[2023-11-07 08:11:07.937226]-Test-Loss:0.2028, Acc:0.9402
[2023-11-07 08:15:58.900916]-Train-Epoch: 179,  Loss: 0.3054, Acc:0.8961
[2023-11-07 08:16:17.629697]-Test-Loss:0.1970, Acc:0.9409
[2023-11-07 08:21:08.434373]-Train-Epoch: 180,  Loss: 0.3041, Acc:0.8967
[2023-11-07 08:21:27.142214]-Test-Loss:0.1810, Acc:0.9447
[2023-11-07 08:26:17.636070]-Train-Epoch: 181,  Loss: 0.3053, Acc:0.8951
[2023-11-07 08:26:36.653660]-Test-Loss:0.1772, Acc:0.9460
[2023-11-07 08:31:28.245756]-Train-Epoch: 182,  Loss: 0.3044, Acc:0.8954
[2023-11-07 08:31:47.075715]-Test-Loss:0.1870, Acc:0.9450
[2023-11-07 08:36:37.429640]-Train-Epoch: 183,  Loss: 0.3029, Acc:0.8974
[2023-11-07 08:36:56.116189]-Test-Loss:0.1897, Acc:0.9427
[2023-11-07 08:41:47.327446]-Train-Epoch: 184,  Loss: 0.3038, Acc:0.8960
[2023-11-07 08:42:06.051602]-Test-Loss:0.1842, Acc:0.9445
[2023-11-07 08:46:55.967603]-Train-Epoch: 185,  Loss: 0.3015, Acc:0.8976
[2023-11-07 08:47:14.434692]-Test-Loss:0.1977, Acc:0.9417
[2023-11-07 08:52:04.581253]-Train-Epoch: 186,  Loss: 0.3007, Acc:0.8977
[2023-11-07 08:52:23.032529]-Test-Loss:0.1921, Acc:0.9423
[2023-11-07 08:57:12.752227]-Train-Epoch: 187,  Loss: 0.2975, Acc:0.8996
[2023-11-07 08:57:31.283248]-Test-Loss:0.1819, Acc:0.9450
[2023-11-07 09:02:22.904926]-Train-Epoch: 188,  Loss: 0.3023, Acc:0.8953
[2023-11-07 09:02:41.172773]-Test-Loss:0.1772, Acc:0.9489
[2023-11-07 09:07:32.433474]-Train-Epoch: 189,  Loss: 0.3035, Acc:0.8960
[2023-11-07 09:07:51.236605]-Test-Loss:0.1784, Acc:0.9454
[2023-11-07 09:12:42.173387]-Train-Epoch: 190,  Loss: 0.2953, Acc:0.8973
[2023-11-07 09:13:00.773389]-Test-Loss:0.1644, Acc:0.9495
[2023-11-07 09:17:51.545619]-Train-Epoch: 191,  Loss: 0.2933, Acc:0.8992
[2023-11-07 09:18:10.205414]-Test-Loss:0.1958, Acc:0.9440
[2023-11-07 09:23:01.899992]-Train-Epoch: 192,  Loss: 0.2926, Acc:0.8983
[2023-11-07 09:23:20.413357]-Test-Loss:0.2133, Acc:0.9385
[2023-11-07 09:28:09.874426]-Train-Epoch: 193,  Loss: 0.2949, Acc:0.8991
[2023-11-07 09:28:28.449614]-Test-Loss:0.1739, Acc:0.9466
[2023-11-07 09:33:19.725323]-Train-Epoch: 194,  Loss: 0.2965, Acc:0.8980
[2023-11-07 09:33:38.449210]-Test-Loss:0.1766, Acc:0.9472
[2023-11-07 09:38:29.272939]-Train-Epoch: 195,  Loss: 0.2954, Acc:0.8982
[2023-11-07 09:38:47.944197]-Test-Loss:0.1896, Acc:0.9460
[2023-11-07 09:43:38.591327]-Train-Epoch: 196,  Loss: 0.2941, Acc:0.8990
[2023-11-07 09:43:57.515657]-Test-Loss:0.1762, Acc:0.9458
[2023-11-07 09:48:47.567154]-Train-Epoch: 197,  Loss: 0.2897, Acc:0.9006
[2023-11-07 09:49:06.489751]-Test-Loss:0.1936, Acc:0.9433
[2023-11-07 09:53:56.892236]-Train-Epoch: 198,  Loss: 0.2902, Acc:0.9015
[2023-11-07 09:54:15.596247]-Test-Loss:0.1758, Acc:0.9444
[2023-11-07 09:59:06.622892]-Train-Epoch: 199,  Loss: 0.2969, Acc:0.8979
[2023-11-07 09:59:25.078723]-Test-Loss:0.1862, Acc:0.9442
[2023-11-07 10:04:15.605150]-Train-Epoch: 200,  Loss: 0.2906, Acc:0.9001
[2023-11-07 10:04:34.588941]-Test-Loss:0.1959, Acc:0.9429
[2023-11-07 10:09:24.920873]-Train-Epoch: 201,  Loss: 0.2921, Acc:0.8990
[2023-11-07 10:09:43.249044]-Test-Loss:0.1789, Acc:0.9474
[2023-11-07 10:14:33.444794]-Train-Epoch: 202,  Loss: 0.2920, Acc:0.8985
[2023-11-07 10:14:52.092657]-Test-Loss:0.1873, Acc:0.9443
[2023-11-07 10:19:42.755298]-Train-Epoch: 203,  Loss: 0.2841, Acc:0.9019
[2023-11-07 10:20:01.541766]-Test-Loss:0.1674, Acc:0.9479
[2023-11-07 10:24:51.873008]-Train-Epoch: 204,  Loss: 0.2836, Acc:0.9022
[2023-11-07 10:25:10.674496]-Test-Loss:0.1791, Acc:0.9472
[2023-11-07 10:30:01.143464]-Train-Epoch: 205,  Loss: 0.2876, Acc:0.9011
[2023-11-07 10:30:19.717131]-Test-Loss:0.1947, Acc:0.9451
[2023-11-07 10:35:09.781533]-Train-Epoch: 206,  Loss: 0.2809, Acc:0.9040
[2023-11-07 10:35:28.228567]-Test-Loss:0.1917, Acc:0.9451
[2023-11-07 10:40:19.256438]-Train-Epoch: 207,  Loss: 0.2805, Acc:0.9037
[2023-11-07 10:40:37.939003]-Test-Loss:0.1941, Acc:0.9455
[2023-11-07 10:45:28.940932]-Train-Epoch: 208,  Loss: 0.2828, Acc:0.9029
[2023-11-07 10:45:47.717246]-Test-Loss:0.1760, Acc:0.9477
[2023-11-07 10:50:37.206315]-Train-Epoch: 209,  Loss: 0.2799, Acc:0.9038
[2023-11-07 10:50:56.167732]-Test-Loss:0.1804, Acc:0.9467
[2023-11-07 10:55:46.681806]-Train-Epoch: 210,  Loss: 0.2818, Acc:0.9023
[2023-11-07 10:56:05.352855]-Test-Loss:0.1759, Acc:0.9480
[2023-11-07 11:00:55.827088]-Train-Epoch: 211,  Loss: 0.2675, Acc:0.9081
[2023-11-07 11:01:14.487401]-Test-Loss:0.1748, Acc:0.9500
[2023-11-07 11:06:05.260122]-Train-Epoch: 212,  Loss: 0.2772, Acc:0.9042
[2023-11-07 11:06:23.661512]-Test-Loss:0.1850, Acc:0.9476
[2023-11-07 11:11:14.287114]-Train-Epoch: 213,  Loss: 0.2809, Acc:0.9028
[2023-11-07 11:11:33.105616]-Test-Loss:0.1883, Acc:0.9456
[2023-11-07 11:16:23.514723]-Train-Epoch: 214,  Loss: 0.2798, Acc:0.9031
[2023-11-07 11:16:42.303139]-Test-Loss:0.1739, Acc:0.9494
[2023-11-07 11:21:32.778609]-Train-Epoch: 215,  Loss: 0.2745, Acc:0.9067
[2023-11-07 11:21:51.389688]-Test-Loss:0.1751, Acc:0.9474
[2023-11-07 11:26:41.821752]-Train-Epoch: 216,  Loss: 0.2705, Acc:0.9074
[2023-11-07 11:27:00.329124]-Test-Loss:0.1725, Acc:0.9478
[2023-11-07 11:31:49.854600]-Train-Epoch: 217,  Loss: 0.2737, Acc:0.9064
[2023-11-07 11:32:08.607098]-Test-Loss:0.1790, Acc:0.9473
[2023-11-07 11:36:59.205392]-Train-Epoch: 218,  Loss: 0.2755, Acc:0.9070
[2023-11-07 11:37:18.377239]-Test-Loss:0.1845, Acc:0.9446
[2023-11-07 11:42:07.281785]-Train-Epoch: 219,  Loss: 0.2729, Acc:0.9066
[2023-11-07 11:42:25.918758]-Test-Loss:0.1749, Acc:0.9483
[2023-11-07 11:47:15.922927]-Train-Epoch: 220,  Loss: 0.2699, Acc:0.9070
[2023-11-07 11:47:34.301541]-Test-Loss:0.1774, Acc:0.9468
[2023-11-07 11:52:26.397861]-Train-Epoch: 221,  Loss: 0.2667, Acc:0.9092
[2023-11-07 11:52:44.918127]-Test-Loss:0.1663, Acc:0.9504
[2023-11-07 11:57:35.909057]-Train-Epoch: 222,  Loss: 0.2678, Acc:0.9077
[2023-11-07 11:57:54.773309]-Test-Loss:0.1705, Acc:0.9489
[2023-11-07 12:02:45.381003]-Train-Epoch: 223,  Loss: 0.2696, Acc:0.9055
[2023-11-07 12:03:04.111841]-Test-Loss:0.1768, Acc:0.9472
[2023-11-07 12:07:54.775756]-Train-Epoch: 224,  Loss: 0.2691, Acc:0.9077
[2023-11-07 12:08:13.695997]-Test-Loss:0.1684, Acc:0.9489
[2023-11-07 12:13:03.623657]-Train-Epoch: 225,  Loss: 0.2667, Acc:0.9094
[2023-11-07 12:13:21.925333]-Test-Loss:0.1882, Acc:0.9445
[2023-11-07 12:18:12.789774]-Train-Epoch: 226,  Loss: 0.2667, Acc:0.9072
[2023-11-07 12:18:31.408596]-Test-Loss:0.1654, Acc:0.9506
[2023-11-07 12:23:21.788010]-Train-Epoch: 227,  Loss: 0.2638, Acc:0.9097
[2023-11-07 12:23:40.123423]-Test-Loss:0.1712, Acc:0.9490
[2023-11-07 12:28:29.298125]-Train-Epoch: 228,  Loss: 0.2666, Acc:0.9080
[2023-11-07 12:28:47.788346]-Test-Loss:0.1744, Acc:0.9474
[2023-11-07 12:33:37.542431]-Train-Epoch: 229,  Loss: 0.2631, Acc:0.9095
[2023-11-07 12:33:56.581358]-Test-Loss:0.1799, Acc:0.9468
[2023-11-07 12:38:46.820608]-Train-Epoch: 230,  Loss: 0.2593, Acc:0.9112
[2023-11-07 12:39:05.205022]-Test-Loss:0.1698, Acc:0.9499
[2023-11-07 12:43:55.078640]-Train-Epoch: 231,  Loss: 0.2552, Acc:0.9112
[2023-11-07 12:44:13.264049]-Test-Loss:0.1776, Acc:0.9492
[2023-11-07 12:49:04.024851]-Train-Epoch: 232,  Loss: 0.2630, Acc:0.9104
[2023-11-07 12:49:22.999084]-Test-Loss:0.1732, Acc:0.9496
[2023-11-07 12:54:13.982172]-Train-Epoch: 233,  Loss: 0.2591, Acc:0.9108
[2023-11-07 12:54:32.509323]-Test-Loss:0.1632, Acc:0.9503
[2023-11-07 12:59:23.300129]-Train-Epoch: 234,  Loss: 0.2515, Acc:0.9135
[2023-11-07 12:59:41.977464]-Test-Loss:0.1869, Acc:0.9457
[2023-11-07 13:04:32.185056]-Train-Epoch: 235,  Loss: 0.2556, Acc:0.9114
[2023-11-07 13:04:50.854015]-Test-Loss:0.1731, Acc:0.9476
[2023-11-07 13:09:42.617328]-Train-Epoch: 236,  Loss: 0.2606, Acc:0.9106
[2023-11-07 13:10:01.081121]-Test-Loss:0.1641, Acc:0.9531
[2023-11-07 13:14:51.856994]-Train-Epoch: 237,  Loss: 0.2509, Acc:0.9123
[2023-11-07 13:15:10.782751]-Test-Loss:0.1724, Acc:0.9481
[2023-11-07 13:20:01.053649]-Train-Epoch: 238,  Loss: 0.2546, Acc:0.9127
[2023-11-07 13:20:19.873293]-Test-Loss:0.1729, Acc:0.9502
[2023-11-07 13:25:09.515340]-Train-Epoch: 239,  Loss: 0.2528, Acc:0.9128
[2023-11-07 13:25:28.446067]-Test-Loss:0.1733, Acc:0.9474
[2023-11-07 13:30:20.359905]-Train-Epoch: 240,  Loss: 0.2521, Acc:0.9126
[2023-11-07 13:30:39.321712]-Test-Loss:0.1741, Acc:0.9474
[2023-11-07 13:35:29.417650]-Train-Epoch: 241,  Loss: 0.2492, Acc:0.9139
[2023-11-07 13:35:48.206149]-Test-Loss:0.1665, Acc:0.9515
[2023-11-07 13:40:38.783029]-Train-Epoch: 242,  Loss: 0.2552, Acc:0.9119
[2023-11-07 13:40:57.391490]-Test-Loss:0.1706, Acc:0.9490
[2023-11-07 13:45:47.209215]-Train-Epoch: 243,  Loss: 0.2473, Acc:0.9151
[2023-11-07 13:46:05.875577]-Test-Loss:0.1695, Acc:0.9537
[2023-11-07 13:50:56.156877]-Train-Epoch: 244,  Loss: 0.2445, Acc:0.9162
[2023-11-07 13:51:14.878022]-Test-Loss:0.1729, Acc:0.9502
[2023-11-07 13:56:05.581924]-Train-Epoch: 245,  Loss: 0.2501, Acc:0.9131
[2023-11-07 13:56:24.361379]-Test-Loss:0.1763, Acc:0.9514
[2023-11-07 14:01:14.986849]-Train-Epoch: 246,  Loss: 0.2455, Acc:0.9160
[2023-11-07 14:01:33.960350]-Test-Loss:0.1709, Acc:0.9497
[2023-11-07 14:06:24.769152]-Train-Epoch: 247,  Loss: 0.2492, Acc:0.9141
[2023-11-07 14:06:43.391046]-Test-Loss:0.1692, Acc:0.9517
[2023-11-07 14:11:33.448325]-Train-Epoch: 248,  Loss: 0.2387, Acc:0.9182
[2023-11-07 14:11:52.283994]-Test-Loss:0.1714, Acc:0.9508
[2023-11-07 14:16:42.237014]-Train-Epoch: 249,  Loss: 0.2426, Acc:0.9164
[2023-11-07 14:17:01.131932]-Test-Loss:0.1527, Acc:0.9529
[2023-11-07 14:21:51.911296]-Train-Epoch: 250,  Loss: 0.2414, Acc:0.9180
[2023-11-07 14:22:10.598278]-Test-Loss:0.1787, Acc:0.9496
[2023-11-07 14:27:00.929094]-Train-Epoch: 251,  Loss: 0.2417, Acc:0.9165
[2023-11-07 14:27:19.787092]-Test-Loss:0.1689, Acc:0.9500
[2023-11-07 14:32:10.330554]-Train-Epoch: 252,  Loss: 0.2442, Acc:0.9166
[2023-11-07 14:32:28.932673]-Test-Loss:0.1747, Acc:0.9510
[2023-11-07 14:37:19.147372]-Train-Epoch: 253,  Loss: 0.2363, Acc:0.9176
[2023-11-07 14:37:38.018522]-Test-Loss:0.1724, Acc:0.9514
[2023-11-07 14:42:27.683582]-Train-Epoch: 254,  Loss: 0.2395, Acc:0.9175
[2023-11-07 14:42:46.473047]-Test-Loss:0.1682, Acc:0.9517
[2023-11-07 14:47:36.781188]-Train-Epoch: 255,  Loss: 0.2388, Acc:0.9178
[2023-11-07 14:47:55.660961]-Test-Loss:0.1802, Acc:0.9479
[2023-11-07 14:52:45.750155]-Train-Epoch: 256,  Loss: 0.2302, Acc:0.9202
[2023-11-07 14:53:04.242240]-Test-Loss:0.1708, Acc:0.9509
[2023-11-07 14:57:55.286042]-Train-Epoch: 257,  Loss: 0.2364, Acc:0.9188
[2023-11-07 14:58:13.915022]-Test-Loss:0.1784, Acc:0.9525
[2023-11-07 15:03:04.798453]-Train-Epoch: 258,  Loss: 0.2326, Acc:0.9201
[2023-11-07 15:03:23.425317]-Test-Loss:0.1624, Acc:0.9533
[2023-11-07 15:08:15.215809]-Train-Epoch: 259,  Loss: 0.2366, Acc:0.9184
[2023-11-07 15:08:34.476211]-Test-Loss:0.1682, Acc:0.9524
[2023-11-07 15:13:25.050095]-Train-Epoch: 260,  Loss: 0.2299, Acc:0.9215
[2023-11-07 15:13:43.244040]-Test-Loss:0.1542, Acc:0.9562
[2023-11-07 15:18:33.639484]-Train-Epoch: 261,  Loss: 0.2304, Acc:0.9204
[2023-11-07 15:18:52.036976]-Test-Loss:0.1577, Acc:0.9544
[2023-11-07 15:23:44.057434]-Train-Epoch: 262,  Loss: 0.2335, Acc:0.9188
[2023-11-07 15:24:02.813099]-Test-Loss:0.1582, Acc:0.9518
[2023-11-07 15:28:53.657205]-Train-Epoch: 263,  Loss: 0.2308, Acc:0.9205
[2023-11-07 15:29:12.541164]-Test-Loss:0.1721, Acc:0.9511
[2023-11-07 15:34:02.043192]-Train-Epoch: 264,  Loss: 0.2289, Acc:0.9213
[2023-11-07 15:34:20.645262]-Test-Loss:0.1632, Acc:0.9535
[2023-11-07 15:39:11.930799]-Train-Epoch: 265,  Loss: 0.2290, Acc:0.9206
[2023-11-07 15:39:30.434200]-Test-Loss:0.1740, Acc:0.9526
[2023-11-07 15:44:20.126688]-Train-Epoch: 266,  Loss: 0.2256, Acc:0.9225
[2023-11-07 15:44:38.520632]-Test-Loss:0.1735, Acc:0.9537
[2023-11-07 15:49:29.732688]-Train-Epoch: 267,  Loss: 0.2240, Acc:0.9235
[2023-11-07 15:49:48.170031]-Test-Loss:0.1646, Acc:0.9535
[2023-11-07 15:54:38.985200]-Train-Epoch: 268,  Loss: 0.2246, Acc:0.9224
[2023-11-07 15:54:57.999583]-Test-Loss:0.1617, Acc:0.9534
[2023-11-07 15:59:49.709564]-Train-Epoch: 269,  Loss: 0.2247, Acc:0.9224
[2023-11-07 16:00:08.214240]-Test-Loss:0.1777, Acc:0.9486
[2023-11-07 16:04:58.942756]-Train-Epoch: 270,  Loss: 0.2235, Acc:0.9221
[2023-11-07 16:05:17.466145]-Test-Loss:0.1673, Acc:0.9515
[2023-11-07 16:10:08.640084]-Train-Epoch: 271,  Loss: 0.2187, Acc:0.9233
[2023-11-07 16:10:27.181035]-Test-Loss:0.1840, Acc:0.9487
[2023-11-07 16:15:16.412985]-Train-Epoch: 272,  Loss: 0.2164, Acc:0.9258
[2023-11-07 16:15:35.473145]-Test-Loss:0.1685, Acc:0.9522
[2023-11-07 16:20:26.101170]-Train-Epoch: 273,  Loss: 0.2214, Acc:0.9231
[2023-11-07 16:20:44.807771]-Test-Loss:0.1706, Acc:0.9542
[2023-11-07 16:25:35.354839]-Train-Epoch: 274,  Loss: 0.2171, Acc:0.9250
[2023-11-07 16:25:52.885127]-Test-Loss:0.1644, Acc:0.9522
[2023-11-07 16:30:24.353562]-Train-Epoch: 275,  Loss: 0.2160, Acc:0.9271
[2023-11-07 16:30:41.186865]-Test-Loss:0.1694, Acc:0.9544
[2023-11-07 16:35:12.976930]-Train-Epoch: 276,  Loss: 0.2174, Acc:0.9256
[2023-11-07 16:35:29.687188]-Test-Loss:0.1646, Acc:0.9541
[2023-11-07 16:40:00.833602]-Train-Epoch: 277,  Loss: 0.2092, Acc:0.9287
[2023-11-07 16:40:17.489062]-Test-Loss:0.1581, Acc:0.9571
[2023-11-07 16:44:48.691593]-Train-Epoch: 278,  Loss: 0.2101, Acc:0.9264
[2023-11-07 16:45:05.314254]-Test-Loss:0.1756, Acc:0.9509
[2023-11-07 16:49:36.735111]-Train-Epoch: 279,  Loss: 0.2139, Acc:0.9264
[2023-11-07 16:49:53.217648]-Test-Loss:0.1710, Acc:0.9501
[2023-11-07 16:54:24.980972]-Train-Epoch: 280,  Loss: 0.2115, Acc:0.9270
[2023-11-07 16:54:41.742315]-Test-Loss:0.1664, Acc:0.9544
[2023-11-07 16:59:13.542906]-Train-Epoch: 281,  Loss: 0.2137, Acc:0.9260
[2023-11-07 16:59:30.332701]-Test-Loss:0.1620, Acc:0.9548
[2023-11-07 17:04:02.042195]-Train-Epoch: 282,  Loss: 0.2124, Acc:0.9280
[2023-11-07 17:04:18.715858]-Test-Loss:0.1558, Acc:0.9547
[2023-11-07 17:08:49.816380]-Train-Epoch: 283,  Loss: 0.2093, Acc:0.9279
[2023-11-07 17:09:06.645629]-Test-Loss:0.1597, Acc:0.9551
[2023-11-07 17:13:38.601621]-Train-Epoch: 284,  Loss: 0.2090, Acc:0.9281
[2023-11-07 17:13:55.157068]-Test-Loss:0.1610, Acc:0.9538
[2023-11-07 17:18:26.823853]-Train-Epoch: 285,  Loss: 0.2072, Acc:0.9299
[2023-11-07 17:18:43.548509]-Test-Loss:0.1632, Acc:0.9548
[2023-11-07 17:23:15.246452]-Train-Epoch: 286,  Loss: 0.2090, Acc:0.9277
[2023-11-07 17:23:32.029079]-Test-Loss:0.1532, Acc:0.9562
[2023-11-07 17:28:04.043325]-Train-Epoch: 287,  Loss: 0.2083, Acc:0.9282
[2023-11-07 17:28:20.665027]-Test-Loss:0.1660, Acc:0.9542
[2023-11-07 17:32:52.422738]-Train-Epoch: 288,  Loss: 0.2017, Acc:0.9307
[2023-11-07 17:33:09.245000]-Test-Loss:0.1732, Acc:0.9532
[2023-11-07 17:37:40.690269]-Train-Epoch: 289,  Loss: 0.2047, Acc:0.9295
[2023-11-07 17:37:57.488727]-Test-Loss:0.1629, Acc:0.9553
[2023-11-07 17:42:28.842830]-Train-Epoch: 290,  Loss: 0.2027, Acc:0.9289
[2023-11-07 17:42:45.447897]-Test-Loss:0.1670, Acc:0.9551
[2023-11-07 17:47:16.931778]-Train-Epoch: 291,  Loss: 0.2046, Acc:0.9297
[2023-11-07 17:47:33.835200]-Test-Loss:0.1732, Acc:0.9535
[2023-11-07 17:52:05.226331]-Train-Epoch: 292,  Loss: 0.2028, Acc:0.9303
[2023-11-07 17:52:21.944259]-Test-Loss:0.1760, Acc:0.9548
[2023-11-07 17:56:53.469966]-Train-Epoch: 293,  Loss: 0.2030, Acc:0.9295
[2023-11-07 17:57:10.185784]-Test-Loss:0.1709, Acc:0.9532
[2023-11-07 18:01:41.756764]-Train-Epoch: 294,  Loss: 0.1990, Acc:0.9301
[2023-11-07 18:01:58.504490]-Test-Loss:0.1647, Acc:0.9552
[2023-11-07 18:06:30.237260]-Train-Epoch: 295,  Loss: 0.1959, Acc:0.9317
[2023-11-07 18:06:47.026029]-Test-Loss:0.1698, Acc:0.9520
[2023-11-07 18:11:18.943261]-Train-Epoch: 296,  Loss: 0.1928, Acc:0.9328
[2023-11-07 18:11:35.669739]-Test-Loss:0.1722, Acc:0.9550
[2023-11-07 18:16:07.660238]-Train-Epoch: 297,  Loss: 0.1975, Acc:0.9320
[2023-11-07 18:16:24.402149]-Test-Loss:0.1740, Acc:0.9520
[2023-11-07 18:20:56.031887]-Train-Epoch: 298,  Loss: 0.1914, Acc:0.9344
[2023-11-07 18:21:12.562387]-Test-Loss:0.1518, Acc:0.9601
[2023-11-07 18:25:44.828334]-Train-Epoch: 299,  Loss: 0.1902, Acc:0.9339
[2023-11-07 18:26:01.521875]-Test-Loss:0.1692, Acc:0.9539
[2023-11-07 18:30:33.859910]-Train-Epoch: 300,  Loss: 0.1962, Acc:0.9319
[2023-11-07 18:30:50.544708]-Test-Loss:0.1546, Acc:0.9577
[2023-11-07 18:35:22.481283]-Train-Epoch: 301,  Loss: 0.1939, Acc:0.9329
[2023-11-07 18:35:39.201955]-Test-Loss:0.1859, Acc:0.9521
[2023-11-07 18:40:02.403825]-Train-Epoch: 302,  Loss: 0.1895, Acc:0.9352
[2023-11-07 18:40:17.384718]-Test-Loss:0.1753, Acc:0.9543
[2023-11-07 18:44:33.375506]-Train-Epoch: 303,  Loss: 0.1817, Acc:0.9380
[2023-11-07 18:44:48.304665]-Test-Loss:0.1535, Acc:0.9591
[2023-11-07 18:49:03.906005]-Train-Epoch: 304,  Loss: 0.1903, Acc:0.9342
[2023-11-07 18:49:18.856444]-Test-Loss:0.1781, Acc:0.9523
[2023-11-07 18:53:34.581976]-Train-Epoch: 305,  Loss: 0.1864, Acc:0.9349
[2023-11-07 18:53:49.521958]-Test-Loss:0.1667, Acc:0.9554
[2023-11-07 18:58:05.126376]-Train-Epoch: 306,  Loss: 0.1827, Acc:0.9369
[2023-11-07 18:58:20.066335]-Test-Loss:0.1607, Acc:0.9577
[2023-11-07 19:02:35.485086]-Train-Epoch: 307,  Loss: 0.1854, Acc:0.9357
[2023-11-07 19:02:50.414342]-Test-Loss:0.1793, Acc:0.9540
[2023-11-07 19:07:05.988725]-Train-Epoch: 308,  Loss: 0.1860, Acc:0.9359
[2023-11-07 19:07:20.929069]-Test-Loss:0.1665, Acc:0.9560
[2023-11-07 19:11:36.650481]-Train-Epoch: 309,  Loss: 0.1793, Acc:0.9376
[2023-11-07 19:11:51.572480]-Test-Loss:0.1605, Acc:0.9563
[2023-11-07 19:16:07.308502]-Train-Epoch: 310,  Loss: 0.1790, Acc:0.9383
[2023-11-07 19:16:22.231704]-Test-Loss:0.1604, Acc:0.9567
[2023-11-07 19:20:37.810309]-Train-Epoch: 311,  Loss: 0.1834, Acc:0.9365
[2023-11-07 19:20:52.769994]-Test-Loss:0.1643, Acc:0.9555
[2023-11-07 19:25:08.388306]-Train-Epoch: 312,  Loss: 0.1794, Acc:0.9381
[2023-11-07 19:25:23.303125]-Test-Loss:0.1521, Acc:0.9577
[2023-11-07 19:29:38.919685]-Train-Epoch: 313,  Loss: 0.1794, Acc:0.9375
[2023-11-07 19:29:53.887515]-Test-Loss:0.1626, Acc:0.9587
[2023-11-07 19:34:09.590330]-Train-Epoch: 314,  Loss: 0.1773, Acc:0.9399
[2023-11-07 19:34:24.512087]-Test-Loss:0.1632, Acc:0.9591
[2023-11-07 19:38:40.121762]-Train-Epoch: 315,  Loss: 0.1776, Acc:0.9381
[2023-11-07 19:38:55.084668]-Test-Loss:0.1567, Acc:0.9570
[2023-11-07 19:43:10.759547]-Train-Epoch: 316,  Loss: 0.1779, Acc:0.9391
[2023-11-07 19:43:25.697264]-Test-Loss:0.1643, Acc:0.9566
[2023-11-07 19:47:41.271204]-Train-Epoch: 317,  Loss: 0.1754, Acc:0.9394
[2023-11-07 19:47:56.205460]-Test-Loss:0.1551, Acc:0.9586
[2023-11-07 19:52:11.885676]-Train-Epoch: 318,  Loss: 0.1747, Acc:0.9393
[2023-11-07 19:52:26.814670]-Test-Loss:0.1620, Acc:0.9579
[2023-11-07 19:56:42.420828]-Train-Epoch: 319,  Loss: 0.1749, Acc:0.9402
[2023-11-07 19:56:57.413828]-Test-Loss:0.1593, Acc:0.9577
[2023-11-07 20:01:13.062461]-Train-Epoch: 320,  Loss: 0.1718, Acc:0.9405
[2023-11-07 20:01:28.035540]-Test-Loss:0.1650, Acc:0.9559
[2023-11-07 20:05:43.721313]-Train-Epoch: 321,  Loss: 0.1734, Acc:0.9409
[2023-11-07 20:05:58.689070]-Test-Loss:0.1574, Acc:0.9592
[2023-11-07 20:10:14.250078]-Train-Epoch: 322,  Loss: 0.1673, Acc:0.9416
[2023-11-07 20:10:29.208058]-Test-Loss:0.1609, Acc:0.9571
[2023-11-07 20:14:44.944193]-Train-Epoch: 323,  Loss: 0.1690, Acc:0.9420
[2023-11-07 20:14:59.919347]-Test-Loss:0.1689, Acc:0.9579
[2023-11-07 20:19:15.502125]-Train-Epoch: 324,  Loss: 0.1648, Acc:0.9424
[2023-11-07 20:19:30.471034]-Test-Loss:0.1643, Acc:0.9597
[2023-11-07 20:23:46.230615]-Train-Epoch: 325,  Loss: 0.1696, Acc:0.9421
[2023-11-07 20:24:01.161919]-Test-Loss:0.1566, Acc:0.9589
[2023-11-07 20:28:16.830198]-Train-Epoch: 326,  Loss: 0.1656, Acc:0.9412
[2023-11-07 20:28:31.761235]-Test-Loss:0.1633, Acc:0.9582
[2023-11-07 20:32:47.463669]-Train-Epoch: 327,  Loss: 0.1666, Acc:0.9420
[2023-11-07 20:33:02.381434]-Test-Loss:0.1620, Acc:0.9604
[2023-11-07 20:37:18.063671]-Train-Epoch: 328,  Loss: 0.1597, Acc:0.9439
[2023-11-07 20:37:33.000339]-Test-Loss:0.1579, Acc:0.9580
[2023-11-07 20:41:48.711952]-Train-Epoch: 329,  Loss: 0.1632, Acc:0.9431
[2023-11-07 20:42:03.657863]-Test-Loss:0.1563, Acc:0.9605
[2023-11-07 20:46:19.388967]-Train-Epoch: 330,  Loss: 0.1620, Acc:0.9440
[2023-11-07 20:46:34.303337]-Test-Loss:0.1573, Acc:0.9579
[2023-11-07 20:50:49.962069]-Train-Epoch: 331,  Loss: 0.1583, Acc:0.9451
[2023-11-07 20:51:04.899331]-Test-Loss:0.1599, Acc:0.9593
[2023-11-07 20:55:20.576980]-Train-Epoch: 332,  Loss: 0.1619, Acc:0.9441
[2023-11-07 20:55:35.558397]-Test-Loss:0.1613, Acc:0.9588
[2023-11-07 20:59:51.157989]-Train-Epoch: 333,  Loss: 0.1555, Acc:0.9458
[2023-11-07 21:00:06.092551]-Test-Loss:0.1504, Acc:0.9600
[2023-11-07 21:04:21.784761]-Train-Epoch: 334,  Loss: 0.1556, Acc:0.9466
[2023-11-07 21:04:36.721962]-Test-Loss:0.1684, Acc:0.9573
[2023-11-07 21:08:52.381838]-Train-Epoch: 335,  Loss: 0.1574, Acc:0.9444
[2023-11-07 21:09:07.323440]-Test-Loss:0.1585, Acc:0.9591
[2023-11-07 21:13:23.044944]-Train-Epoch: 336,  Loss: 0.1554, Acc:0.9457
[2023-11-07 21:13:38.000773]-Test-Loss:0.1578, Acc:0.9586
[2023-11-07 21:17:53.666506]-Train-Epoch: 337,  Loss: 0.1565, Acc:0.9467
[2023-11-07 21:18:08.651161]-Test-Loss:0.1606, Acc:0.9588
[2023-11-07 21:22:24.370276]-Train-Epoch: 338,  Loss: 0.1570, Acc:0.9457
[2023-11-07 21:22:39.300487]-Test-Loss:0.1518, Acc:0.9600
[2023-11-07 21:26:54.974001]-Train-Epoch: 339,  Loss: 0.1502, Acc:0.9479
[2023-11-07 21:27:09.928457]-Test-Loss:0.1632, Acc:0.9587
[2023-11-07 21:31:25.674576]-Train-Epoch: 340,  Loss: 0.1508, Acc:0.9472
[2023-11-07 21:31:40.644851]-Test-Loss:0.1581, Acc:0.9620
[2023-11-07 21:35:56.347089]-Train-Epoch: 341,  Loss: 0.1486, Acc:0.9478
[2023-11-07 21:36:11.313377]-Test-Loss:0.1661, Acc:0.9587
[2023-11-07 21:40:26.996684]-Train-Epoch: 342,  Loss: 0.1502, Acc:0.9473
[2023-11-07 21:40:41.960022]-Test-Loss:0.1688, Acc:0.9594
[2023-11-07 21:44:57.682340]-Train-Epoch: 343,  Loss: 0.1466, Acc:0.9496
[2023-11-07 21:45:12.666059]-Test-Loss:0.1563, Acc:0.9605
[2023-11-07 21:49:28.278723]-Train-Epoch: 344,  Loss: 0.1509, Acc:0.9472
[2023-11-07 21:49:43.251947]-Test-Loss:0.1498, Acc:0.9625
[2023-11-07 21:53:59.013656]-Train-Epoch: 345,  Loss: 0.1448, Acc:0.9500
[2023-11-07 21:54:13.947019]-Test-Loss:0.1598, Acc:0.9613
[2023-11-07 21:58:29.624222]-Train-Epoch: 346,  Loss: 0.1468, Acc:0.9488
[2023-11-07 21:58:44.593236]-Test-Loss:0.1577, Acc:0.9628
[2023-11-07 22:03:00.371509]-Train-Epoch: 347,  Loss: 0.1432, Acc:0.9500
[2023-11-07 22:03:15.278666]-Test-Loss:0.1580, Acc:0.9624
[2023-11-07 22:07:30.904911]-Train-Epoch: 348,  Loss: 0.1453, Acc:0.9498
[2023-11-07 22:07:45.812214]-Test-Loss:0.1630, Acc:0.9593
[2023-11-07 22:12:01.469896]-Train-Epoch: 349,  Loss: 0.1397, Acc:0.9510
[2023-11-07 22:12:16.400652]-Test-Loss:0.1529, Acc:0.9619
[2023-11-07 22:16:32.098259]-Train-Epoch: 350,  Loss: 0.1398, Acc:0.9514
[2023-11-07 22:16:47.027567]-Test-Loss:0.1488, Acc:0.9631
[2023-11-07 22:21:02.667794]-Train-Epoch: 351,  Loss: 0.1465, Acc:0.9496
[2023-11-07 22:21:17.606320]-Test-Loss:0.1500, Acc:0.9630
[2023-11-07 22:25:33.291845]-Train-Epoch: 352,  Loss: 0.1408, Acc:0.9522
[2023-11-07 22:25:48.259315]-Test-Loss:0.1573, Acc:0.9623
[2023-11-07 22:30:03.963493]-Train-Epoch: 353,  Loss: 0.1392, Acc:0.9516
[2023-11-07 22:30:18.946941]-Test-Loss:0.1594, Acc:0.9624
[2023-11-07 22:34:34.636022]-Train-Epoch: 354,  Loss: 0.1380, Acc:0.9527
[2023-11-07 22:34:49.561957]-Test-Loss:0.1581, Acc:0.9629
[2023-11-07 22:39:05.163078]-Train-Epoch: 355,  Loss: 0.1394, Acc:0.9513
[2023-11-07 22:39:20.089897]-Test-Loss:0.1619, Acc:0.9615
[2023-11-07 22:43:35.767184]-Train-Epoch: 356,  Loss: 0.1341, Acc:0.9532
[2023-11-07 22:43:50.701997]-Test-Loss:0.1669, Acc:0.9602
[2023-11-07 22:48:06.156808]-Train-Epoch: 357,  Loss: 0.1370, Acc:0.9526
[2023-11-07 22:48:21.075796]-Test-Loss:0.1629, Acc:0.9621
[2023-11-07 22:52:36.807026]-Train-Epoch: 358,  Loss: 0.1322, Acc:0.9536
[2023-11-07 22:52:51.740473]-Test-Loss:0.1625, Acc:0.9616
[2023-11-07 22:57:07.421821]-Train-Epoch: 359,  Loss: 0.1364, Acc:0.9527
[2023-11-07 22:57:22.406585]-Test-Loss:0.1577, Acc:0.9619
[2023-11-07 23:01:38.117473]-Train-Epoch: 360,  Loss: 0.1306, Acc:0.9553
[2023-11-07 23:01:53.058361]-Test-Loss:0.1602, Acc:0.9606
[2023-11-07 23:06:08.796831]-Train-Epoch: 361,  Loss: 0.1278, Acc:0.9556
[2023-11-07 23:06:23.765061]-Test-Loss:0.1596, Acc:0.9616
[2023-11-07 23:10:39.377790]-Train-Epoch: 362,  Loss: 0.1303, Acc:0.9553
[2023-11-07 23:10:54.324618]-Test-Loss:0.1552, Acc:0.9632
[2023-11-07 23:15:10.122043]-Train-Epoch: 363,  Loss: 0.1307, Acc:0.9537
[2023-11-07 23:15:25.048927]-Test-Loss:0.1520, Acc:0.9620
[2023-11-07 23:19:40.681901]-Train-Epoch: 364,  Loss: 0.1280, Acc:0.9556
[2023-11-07 23:19:55.617588]-Test-Loss:0.1563, Acc:0.9632
[2023-11-07 23:24:11.358033]-Train-Epoch: 365,  Loss: 0.1288, Acc:0.9559
[2023-11-07 23:24:26.279592]-Test-Loss:0.1549, Acc:0.9622
[2023-11-07 23:28:41.928244]-Train-Epoch: 366,  Loss: 0.1293, Acc:0.9549
[2023-11-07 23:28:56.846469]-Test-Loss:0.1584, Acc:0.9626
[2023-11-07 23:33:12.608458]-Train-Epoch: 367,  Loss: 0.1248, Acc:0.9568
[2023-11-07 23:33:27.574341]-Test-Loss:0.1589, Acc:0.9616
[2023-11-07 23:37:43.220463]-Train-Epoch: 368,  Loss: 0.1289, Acc:0.9545
[2023-11-07 23:37:58.125957]-Test-Loss:0.1573, Acc:0.9617
[2023-11-07 23:42:13.862306]-Train-Epoch: 369,  Loss: 0.1241, Acc:0.9567
[2023-11-07 23:42:28.777119]-Test-Loss:0.1589, Acc:0.9621
[2023-11-07 23:46:44.429126]-Train-Epoch: 370,  Loss: 0.1239, Acc:0.9574
[2023-11-07 23:46:59.389606]-Test-Loss:0.1559, Acc:0.9620
[2023-11-07 23:51:15.132744]-Train-Epoch: 371,  Loss: 0.1251, Acc:0.9571
[2023-11-07 23:51:30.106768]-Test-Loss:0.1538, Acc:0.9634
[2023-11-07 23:55:45.879922]-Train-Epoch: 372,  Loss: 0.1221, Acc:0.9576
[2023-11-07 23:56:00.856243]-Test-Loss:0.1620, Acc:0.9632
[2023-11-08 00:00:16.552696]-Train-Epoch: 373,  Loss: 0.1234, Acc:0.9570
[2023-11-08 00:00:31.469791]-Test-Loss:0.1572, Acc:0.9628
[2023-11-08 00:04:47.241915]-Train-Epoch: 374,  Loss: 0.1190, Acc:0.9588
[2023-11-08 00:05:02.165302]-Test-Loss:0.1586, Acc:0.9627
[2023-11-08 00:09:17.885200]-Train-Epoch: 375,  Loss: 0.1159, Acc:0.9605
[2023-11-08 00:09:32.802427]-Test-Loss:0.1561, Acc:0.9638
[2023-11-08 00:13:48.596546]-Train-Epoch: 376,  Loss: 0.1159, Acc:0.9598
[2023-11-08 00:14:03.538502]-Test-Loss:0.1583, Acc:0.9648
[2023-11-08 00:18:19.239521]-Train-Epoch: 377,  Loss: 0.1208, Acc:0.9584
[2023-11-08 00:18:34.168833]-Test-Loss:0.1570, Acc:0.9632
[2023-11-08 00:22:49.683662]-Train-Epoch: 378,  Loss: 0.1165, Acc:0.9599
[2023-11-08 00:23:04.630201]-Test-Loss:0.1593, Acc:0.9636
[2023-11-08 00:27:20.360159]-Train-Epoch: 379,  Loss: 0.1195, Acc:0.9585
[2023-11-08 00:27:35.355076]-Test-Loss:0.1586, Acc:0.9641
[2023-11-08 00:31:51.095196]-Train-Epoch: 380,  Loss: 0.1166, Acc:0.9590
[2023-11-08 00:32:06.064869]-Test-Loss:0.1586, Acc:0.9639
[2023-11-08 00:36:21.820230]-Train-Epoch: 381,  Loss: 0.1108, Acc:0.9608
[2023-11-08 00:36:36.779211]-Test-Loss:0.1605, Acc:0.9634
[2023-11-08 00:40:52.390631]-Train-Epoch: 382,  Loss: 0.1110, Acc:0.9617
[2023-11-08 00:41:07.331056]-Test-Loss:0.1618, Acc:0.9627
[2023-11-08 00:45:23.073215]-Train-Epoch: 383,  Loss: 0.1163, Acc:0.9602
[2023-11-08 00:45:37.995883]-Test-Loss:0.1574, Acc:0.9651
[2023-11-08 00:49:53.660697]-Train-Epoch: 384,  Loss: 0.1102, Acc:0.9619
[2023-11-08 00:50:08.650250]-Test-Loss:0.1513, Acc:0.9650
[2023-11-08 00:54:24.401336]-Train-Epoch: 385,  Loss: 0.1106, Acc:0.9616
[2023-11-08 00:54:39.347182]-Test-Loss:0.1563, Acc:0.9635
[2023-11-08 00:58:54.998500]-Train-Epoch: 386,  Loss: 0.1124, Acc:0.9616
[2023-11-08 00:59:09.976571]-Test-Loss:0.1568, Acc:0.9646
[2023-11-08 01:03:25.793625]-Train-Epoch: 387,  Loss: 0.1097, Acc:0.9625
[2023-11-08 01:03:40.706061]-Test-Loss:0.1547, Acc:0.9641
[2023-11-08 01:07:56.421205]-Train-Epoch: 388,  Loss: 0.1102, Acc:0.9619
[2023-11-08 01:08:11.345582]-Test-Loss:0.1560, Acc:0.9642
[2023-11-08 01:12:27.123540]-Train-Epoch: 389,  Loss: 0.1081, Acc:0.9627
[2023-11-08 01:12:42.088986]-Test-Loss:0.1574, Acc:0.9632
[2023-11-08 01:16:57.756944]-Train-Epoch: 390,  Loss: 0.1071, Acc:0.9632
[2023-11-08 01:17:12.711774]-Test-Loss:0.1601, Acc:0.9640
[2023-11-08 01:21:28.513369]-Train-Epoch: 391,  Loss: 0.1044, Acc:0.9631
[2023-11-08 01:21:43.462976]-Test-Loss:0.1591, Acc:0.9638
[2023-11-08 01:25:59.235669]-Train-Epoch: 392,  Loss: 0.1083, Acc:0.9634
[2023-11-08 01:26:14.217898]-Test-Loss:0.1586, Acc:0.9640
[2023-11-08 01:30:29.875986]-Train-Epoch: 393,  Loss: 0.1094, Acc:0.9624
[2023-11-08 01:30:44.851574]-Test-Loss:0.1573, Acc:0.9652
[2023-11-08 01:35:00.603917]-Train-Epoch: 394,  Loss: 0.1065, Acc:0.9633
[2023-11-08 01:35:15.531804]-Test-Loss:0.1545, Acc:0.9656
[2023-11-08 01:39:31.159950]-Train-Epoch: 395,  Loss: 0.1044, Acc:0.9637
[2023-11-08 01:39:46.116897]-Test-Loss:0.1541, Acc:0.9661
[2023-11-08 01:44:01.936004]-Train-Epoch: 396,  Loss: 0.1005, Acc:0.9651
[2023-11-08 01:44:16.899439]-Test-Loss:0.1560, Acc:0.9663
[2023-11-08 01:48:32.562191]-Train-Epoch: 397,  Loss: 0.1033, Acc:0.9650
[2023-11-08 01:48:47.526746]-Test-Loss:0.1644, Acc:0.9649
[2023-11-08 01:53:03.228713]-Train-Epoch: 398,  Loss: 0.1045, Acc:0.9637
[2023-11-08 01:53:18.151361]-Test-Loss:0.1548, Acc:0.9654
[2023-11-08 01:57:33.882896]-Train-Epoch: 399,  Loss: 0.1052, Acc:0.9637
[2023-11-08 01:57:48.809391]-Test-Loss:0.1532, Acc:0.9653
[2023-11-08 02:02:04.487440]-Train-Epoch: 400,  Loss: 0.1013, Acc:0.9651
[2023-11-08 02:02:19.406125]-Test-Loss:0.1581, Acc:0.9655
[2023-11-08 02:06:35.195367]-Train-Epoch: 401,  Loss: 0.1040, Acc:0.9644
[2023-11-08 02:06:50.116229]-Test-Loss:0.1537, Acc:0.9648
[2023-11-08 02:11:05.867029]-Train-Epoch: 402,  Loss: 0.1016, Acc:0.9657
[2023-11-08 02:11:20.827918]-Test-Loss:0.1574, Acc:0.9637
[2023-11-08 02:15:36.619594]-Train-Epoch: 403,  Loss: 0.1037, Acc:0.9645
[2023-11-08 02:15:51.585798]-Test-Loss:0.1571, Acc:0.9663
[2023-11-08 02:20:07.148321]-Train-Epoch: 404,  Loss: 0.1023, Acc:0.9643
[2023-11-08 02:20:22.113779]-Test-Loss:0.1542, Acc:0.9658
[2023-11-08 02:24:37.813063]-Train-Epoch: 405,  Loss: 0.0992, Acc:0.9664
[2023-11-08 02:24:52.731505]-Test-Loss:0.1570, Acc:0.9653
[2023-11-08 02:29:08.374871]-Train-Epoch: 406,  Loss: 0.1020, Acc:0.9655
[2023-11-08 02:29:23.340635]-Test-Loss:0.1570, Acc:0.9658
[2023-11-08 02:33:39.102352]-Train-Epoch: 407,  Loss: 0.0997, Acc:0.9652
[2023-11-08 02:33:54.056666]-Test-Loss:0.1561, Acc:0.9653
[2023-11-08 02:38:09.717554]-Train-Epoch: 408,  Loss: 0.0978, Acc:0.9663
[2023-11-08 02:38:24.662550]-Test-Loss:0.1584, Acc:0.9653
[2023-11-08 02:42:40.332068]-Train-Epoch: 409,  Loss: 0.0961, Acc:0.9673
[2023-11-08 02:42:55.262214]-Test-Loss:0.1601, Acc:0.9650
[2023-11-08 02:47:10.844672]-Train-Epoch: 410,  Loss: 0.0955, Acc:0.9677
[2023-11-08 02:47:25.799102]-Test-Loss:0.1589, Acc:0.9650
[2023-11-08 02:51:41.456629]-Train-Epoch: 411,  Loss: 0.0946, Acc:0.9671
[2023-11-08 02:51:56.406949]-Test-Loss:0.1597, Acc:0.9633
[2023-11-08 02:56:12.121751]-Train-Epoch: 412,  Loss: 0.0952, Acc:0.9672
[2023-11-08 02:56:27.052246]-Test-Loss:0.1583, Acc:0.9654
[2023-11-08 03:00:42.700319]-Train-Epoch: 413,  Loss: 0.0976, Acc:0.9665
[2023-11-08 03:00:57.637718]-Test-Loss:0.1585, Acc:0.9655
[2023-11-08 03:05:13.293411]-Train-Epoch: 414,  Loss: 0.0929, Acc:0.9679
[2023-11-08 03:05:28.241416]-Test-Loss:0.1605, Acc:0.9647
[2023-11-08 03:09:43.885040]-Train-Epoch: 415,  Loss: 0.0939, Acc:0.9676
[2023-11-08 03:09:58.816479]-Test-Loss:0.1592, Acc:0.9646
[2023-11-08 03:14:14.521902]-Train-Epoch: 416,  Loss: 0.0952, Acc:0.9677
[2023-11-08 03:14:29.465262]-Test-Loss:0.1566, Acc:0.9651
[2023-11-08 03:18:45.079292]-Train-Epoch: 417,  Loss: 0.0933, Acc:0.9686
[2023-11-08 03:19:00.030266]-Test-Loss:0.1540, Acc:0.9661
[2023-11-08 03:23:15.703821]-Train-Epoch: 418,  Loss: 0.0913, Acc:0.9680
[2023-11-08 03:23:30.649676]-Test-Loss:0.1578, Acc:0.9655
[2023-11-08 03:27:46.107768]-Train-Epoch: 419,  Loss: 0.0919, Acc:0.9677
[2023-11-08 03:28:01.034418]-Test-Loss:0.1617, Acc:0.9665
[2023-11-08 03:32:16.684477]-Train-Epoch: 420,  Loss: 0.0927, Acc:0.9680
[2023-11-08 03:32:31.619942]-Test-Loss:0.1589, Acc:0.9658
[2023-11-08 03:36:47.303428]-Train-Epoch: 421,  Loss: 0.0910, Acc:0.9681
[2023-11-08 03:37:02.258923]-Test-Loss:0.1573, Acc:0.9663
[2023-11-08 03:41:18.026029]-Train-Epoch: 422,  Loss: 0.0919, Acc:0.9685
[2023-11-08 03:41:33.017306]-Test-Loss:0.1577, Acc:0.9667
[2023-11-08 03:45:48.654138]-Train-Epoch: 423,  Loss: 0.0876, Acc:0.9701
[2023-11-08 03:46:03.649554]-Test-Loss:0.1550, Acc:0.9666
[2023-11-08 03:50:19.261087]-Train-Epoch: 424,  Loss: 0.0896, Acc:0.9690
[2023-11-08 03:50:34.190479]-Test-Loss:0.1543, Acc:0.9663
[2023-11-08 03:54:49.945563]-Train-Epoch: 425,  Loss: 0.0903, Acc:0.9688
[2023-11-08 03:55:04.920338]-Test-Loss:0.1541, Acc:0.9660
[2023-11-08 03:59:20.476541]-Train-Epoch: 426,  Loss: 0.0891, Acc:0.9690
[2023-11-08 03:59:35.426819]-Test-Loss:0.1537, Acc:0.9660
[2023-11-08 04:03:51.121259]-Train-Epoch: 427,  Loss: 0.0922, Acc:0.9680
[2023-11-08 04:04:06.074215]-Test-Loss:0.1538, Acc:0.9657
[2023-11-08 04:08:21.692702]-Train-Epoch: 428,  Loss: 0.0917, Acc:0.9691
[2023-11-08 04:08:36.668770]-Test-Loss:0.1570, Acc:0.9659
[2023-11-08 04:12:52.390883]-Train-Epoch: 429,  Loss: 0.0923, Acc:0.9685
[2023-11-08 04:13:07.358929]-Test-Loss:0.1537, Acc:0.9656
[2023-11-08 04:17:22.999404]-Train-Epoch: 430,  Loss: 0.0916, Acc:0.9686
[2023-11-08 04:17:37.926991]-Test-Loss:0.1579, Acc:0.9661
[2023-11-08 04:21:53.400612]-Train-Epoch: 431,  Loss: 0.0889, Acc:0.9695
[2023-11-08 04:22:08.347348]-Test-Loss:0.1518, Acc:0.9658
[2023-11-08 04:26:24.055788]-Train-Epoch: 432,  Loss: 0.0916, Acc:0.9692
[2023-11-08 04:26:39.018694]-Test-Loss:0.1557, Acc:0.9658
[2023-11-08 04:30:54.555383]-Train-Epoch: 433,  Loss: 0.0893, Acc:0.9701
[2023-11-08 04:31:09.515779]-Test-Loss:0.1561, Acc:0.9664
[2023-11-08 04:35:25.206847]-Train-Epoch: 434,  Loss: 0.0877, Acc:0.9703
[2023-11-08 04:35:40.200923]-Test-Loss:0.1588, Acc:0.9652
[2023-11-08 04:39:55.769841]-Train-Epoch: 435,  Loss: 0.0903, Acc:0.9695
[2023-11-08 04:40:10.733179]-Test-Loss:0.1555, Acc:0.9669
[2023-11-08 04:44:26.423845]-Train-Epoch: 436,  Loss: 0.0881, Acc:0.9699
[2023-11-08 04:44:41.354788]-Test-Loss:0.1563, Acc:0.9652
[2023-11-08 04:48:56.965147]-Train-Epoch: 437,  Loss: 0.0890, Acc:0.9689
[2023-11-08 04:49:11.944971]-Test-Loss:0.1568, Acc:0.9659
[2023-11-08 04:53:27.605690]-Train-Epoch: 438,  Loss: 0.0902, Acc:0.9697
[2023-11-08 04:53:42.528903]-Test-Loss:0.1577, Acc:0.9660
[2023-11-08 04:57:58.174524]-Train-Epoch: 439,  Loss: 0.0884, Acc:0.9698
[2023-11-08 04:58:13.138854]-Test-Loss:0.1550, Acc:0.9665
[2023-11-08 05:02:28.790470]-Train-Epoch: 440,  Loss: 0.0912, Acc:0.9689
[2023-11-08 05:02:43.759042]-Test-Loss:0.1580, Acc:0.9656
[2023-11-08 05:06:59.368676]-Train-Epoch: 441,  Loss: 0.0915, Acc:0.9697
[2023-11-08 05:07:14.347194]-Test-Loss:0.1599, Acc:0.9651
[2023-11-08 05:11:30.005552]-Train-Epoch: 442,  Loss: 0.0881, Acc:0.9692
[2023-11-08 05:11:44.939775]-Test-Loss:0.1578, Acc:0.9662
[2023-11-08 05:16:00.658545]-Train-Epoch: 443,  Loss: 0.0892, Acc:0.9698
[2023-11-08 05:16:15.584728]-Test-Loss:0.1540, Acc:0.9668
[2023-11-08 05:20:31.156107]-Train-Epoch: 444,  Loss: 0.0877, Acc:0.9703
[2023-11-08 05:20:46.128479]-Test-Loss:0.1554, Acc:0.9669
[2023-11-08 05:25:01.860486]-Train-Epoch: 445,  Loss: 0.0923, Acc:0.9686
[2023-11-08 05:25:16.812150]-Test-Loss:0.1604, Acc:0.9658
[2023-11-08 05:29:32.495499]-Train-Epoch: 446,  Loss: 0.0894, Acc:0.9697
[2023-11-08 05:29:47.467767]-Test-Loss:0.1558, Acc:0.9663
[2023-11-08 05:34:03.150296]-Train-Epoch: 447,  Loss: 0.0900, Acc:0.9701
[2023-11-08 05:34:18.070609]-Test-Loss:0.1559, Acc:0.9667
[2023-11-08 05:38:33.665822]-Train-Epoch: 448,  Loss: 0.0921, Acc:0.9681
[2023-11-08 05:38:48.587412]-Test-Loss:0.1590, Acc:0.9652
[2023-11-08 05:43:04.331087]-Train-Epoch: 449,  Loss: 0.0882, Acc:0.9706
[2023-11-08 05:43:19.287703]-Test-Loss:0.1552, Acc:0.9662
[2023-11-08 05:47:34.908535]-Train-Epoch: 450,  Loss: 0.0865, Acc:0.9706
[2023-11-08 05:47:49.826844]-Test-Loss:0.1545, Acc:0.9665
[2023-11-08 05:47:49.828739]-Finished-Acc:0.9669
